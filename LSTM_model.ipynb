{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinzhouLi/Toxic_Language_Detection_in_Social_Media/blob/main/LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! git clone https://github.com/XinzhouLi/Toxic_Language_Detection_in_Social_Media.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "yr7kCVmDXkwX"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "from torch import nn, optim\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def unify_format(text):\n",
        "\treturn re.sub(r\"[^a-zA-Z0-9]\",\" \",text).lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Cleaning\n",
        "class ToxicDataset(data.Dataset): \n",
        "\tdef __init__(self, csv_file):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# Read data in\n",
        "\t\tself.dataframe = pd.read_csv(\"train.csv\", iterator=True, header=0,encoding='utf-8', usecols=['comment_text','toxic'])\n",
        "\t\t# initialize pandas dataframe to store the data\n",
        "\t\tself.dataframe = pd.DataFrame(self.dataframe.read())\n",
        "\t\tself.dataframe.convert_dtypes()\n",
        "\t\t# Clean the data using regular expersion, only reserve letter and number\n",
        "\t\tself.dataframe['comment_text'] = self.dataframe['comment_text'].apply(unify_format)\n",
        "\t\t\n",
        "\t\tprint(self.dataframe)\n",
        "\n",
        "\t# override the getiem function, return tuple contains comment and label\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tcomment, label = self.dataframe.iat[index,0], self.dataframe.iat[index,1]\n",
        "\t\treturn comment,label\n",
        "\n",
        "\t# Override the len function, return the length of the dataframe\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.dataframe.loc[:,['comment_text']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             comment_text  toxic\n",
            "0       explanation  why the edits made under my usern...      0\n",
            "1       d aww  he matches this background colour i m s...      0\n",
            "2       hey man  i m really not trying to edit war  it...      0\n",
            "3          more  i can t make any real suggestions on ...      0\n",
            "4       you  sir  are my hero  any chance you remember...      0\n",
            "...                                                   ...    ...\n",
            "159566        and for the second time of asking  when ...      0\n",
            "159567  you should be ashamed of yourself     that is ...      0\n",
            "159568  spitzer     umm  theres no actual article for ...      0\n",
            "159569  and it looks like it was actually you who put ...      0\n",
            "159570     and     i really don t think you understand...      0\n",
            "\n",
            "[159571 rows x 2 columns]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'ToxicDataset' object has no attribute '__len__'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32md:\\All kind of WorkingSpaces\\Toxic_Language_Detection_in_Social_Media\\LSTM_model.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/All%20kind%20of%20WorkingSpaces/Toxic_Language_Detection_in_Social_Media/LSTM_model.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m ToxicDataset(\u001b[39m\"\u001b[39m\u001b[39mtrain.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/All%20kind%20of%20WorkingSpaces/Toxic_Language_Detection_in_Social_Media/LSTM_model.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(train_dataset\u001b[39m.\u001b[39;49m\u001b[39m__len__\u001b[39;49m())\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/All%20kind%20of%20WorkingSpaces/Toxic_Language_Detection_in_Social_Media/LSTM_model.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_dataloader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/All%20kind%20of%20WorkingSpaces/Toxic_Language_Detection_in_Social_Media/LSTM_model.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(train_dataloader\u001b[39m.\u001b[39mdataset)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'ToxicDataset' object has no attribute '__len__'"
          ]
        }
      ],
      "source": [
        "train_dataset = ToxicDataset(\"train.csv\")\n",
        "print(train_dataset.__len__())\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "print(train_dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOMdefZJbtrcS+AakPmNnpu",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
